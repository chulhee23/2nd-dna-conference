{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 생성 함수\n",
    "def file_write(df,name):\n",
    "    \n",
    "    t = pd.Timestamp.now()\n",
    "    fname = str(name) + str(t.month) + str(t.day) + \".csv\"\n",
    "    \n",
    "    print(str(name) + '파일 생성 | 이름 : ' + str(fname))\n",
    "\n",
    "    df.to_csv(fname,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login 함수 생성\n",
    "def login(id_,password):\n",
    "    browser.find_element_by_name('userid').send_keys(str(id_))\n",
    "    browser.find_element_by_name('password').send_keys(str(password))\n",
    "    browser.find_element_by_xpath('//*[@id=\"container\"]/form/p[3]/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "def cleanText(readData):\n",
    "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', ' ', readData) # 특문제거\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lecture_update(id_,password):\n",
    "    \n",
    "    # Browser 켜기\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get('https://everytime.kr/timetable')\n",
    "    \n",
    "    # login\n",
    "    login(id_,password)\n",
    "    sleep(3)\n",
    "        \n",
    "    # 가끔 팝업뜨는거 닫아주기\n",
    "    try:\n",
    "        browser.find_element_by_xpath('//*[@id=\"sheet\"]/ul/li[3]/a').click()\n",
    "    except:\n",
    "        print('팝업 안닫혔음, 확인부탁')\n",
    "    \n",
    "    # 검색 클릭\n",
    "    browser.find_element_by_xpath('//*[@id=\"container\"]/ul/li[1]').click()\n",
    "        \n",
    "    # 스크롤 내리기\n",
    "    scr1=browser.find_element_by_xpath('//*[@id=\"subjects\"]/div[2]')\n",
    "    \n",
    "    for i in range(100):\n",
    "        browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scr1)\n",
    "        sleep(3)\n",
    "    \n",
    "    # 에타 과목 정보 저장\n",
    "    tables = browser.find_elements_by_tag_name(\"tr\")\n",
    "    # 이 과목 평점 저장\n",
    "    stars = browser.find_elements_by_class_name('star')\n",
    "    \n",
    "    # 점수랑 링크 가져오는 코드\n",
    "    scores=[]\n",
    "    links=[]\n",
    "    for table in stars :\n",
    "        scores.append(table.get_attribute('title'))\n",
    "        links.append(table.get_attribute('href'))\n",
    "        \n",
    "    # 테이블이, 3번행부터 정보가 있고, 2918행 이후로는 의미없는 행이길래 제외 (이거 자주 바뀜 확인해줘야 할듯)\n",
    "    # 테이블에서 세부정보 뽑는 코드\n",
    "    tables=tables[3:3000]\n",
    "    grades=[] # 추천학년\n",
    "    categories=[] # 수업 분류(전공,교양)\n",
    "    codes=[] # 과목코드\n",
    "    names=[] # 수업 이름\n",
    "    profs=[] # 교수 이름\n",
    "    weights=[] # 학점(1,2,3)\n",
    "    times=[] # 시간\n",
    "    competitiors=[] # 에타 시간표에 담은인원\n",
    "    remarks=[]\n",
    "    \n",
    "    print('과목 정보 추출')\n",
    "    for elem in tqdm_notebook(tables):\n",
    "        splited=elem.find_elements_by_tag_name('td')\n",
    "        try:\n",
    "            grades.append(splited[0].text)\n",
    "            categories.append(splited[1].text)\n",
    "            codes.append(splited[2].text)\n",
    "            names.append(splited[3].text)\n",
    "            profs.append(splited[4].text)\n",
    "            weights.append(splited[5].text)\n",
    "            times.append(splited[8].text)\n",
    "            competitiors.append(splited[10].text)\n",
    "            remarks.append(splited[11].text)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # 뽑은 리스트들을 df로 바꿔줬음\n",
    "    dfs=[names,codes,scores,categories,profs,times,grades,weights,competitiors,remarks,links]\n",
    "    df=pd.DataFrame()\n",
    "    for cols in dfs:\n",
    "        df=pd.concat([df,pd.Series(cols)],axis=1)\n",
    "    del tables\n",
    "    \n",
    "    # 칼럼 이름 만들어줌\n",
    "    df.columns=['class_name','class_code','score','category','professor','time',\n",
    "            'recommend_year','weight','competitor','remarks','link']\n",
    "    \n",
    "    # 아까 위에서 형식 제대로 안지켜진 데이터들 떨굼\n",
    "    df.dropna(inplace=True)\n",
    "    lecture=df.copy()\n",
    "    \n",
    "    file_write(lecture,lecture)\n",
    "\n",
    "\n",
    "    #return df2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_crawl(link_text):\n",
    "    ## Selenium\n",
    "    browser.get(link_text)\n",
    "    sleep(0.5) # 로딩 기다리기\n",
    "    # 리뷰 내용만 추출\n",
    "    reg=re.compile('[0-9]')\n",
    "    reviews={}\n",
    "    sleep(2) # 로딩 기다리기 \n",
    "    tb=browser.find_element_by_class_name('articles')\n",
    "    art_table=tb.find_elements_by_tag_name('article')\n",
    "\n",
    "    for element in art_table :\n",
    "        reviews[element.find_element_by_class_name('text').text]=(float(''.join(reg.findall(element.find_element_by_class_name('on').get_attribute('style'))))*0.05)\n",
    "\n",
    "    # 소스 뺴와서 파싱\n",
    "    table=bs(browser.page_source,'xml')\n",
    "    heads=table.find('div',class_='side head')\n",
    "    \n",
    "    # 제목, 교수 내용 추출\n",
    "    class_name=(heads.find('h2').text)\n",
    "    prof_name=(heads.find('span').text)\n",
    "\n",
    "    # 강의평 테이블 추출\n",
    "    articles=table.find('div',class_='side article')\n",
    "\n",
    "    # 강의평의 평균 평점 내용 추출\n",
    "    mean_score=float(articles.find('span',class_='value').text)\n",
    "\n",
    "    # 강의평 중 세부 테이블 추출\n",
    "    details=articles.find('div',class_='details')\n",
    "\n",
    "    # 강의평 중 세부 내용 추출\n",
    "    labels=details.find_all('label')\n",
    "    detail=details.find_all('span')\n",
    "    detail_type={}\n",
    "    for l,d in zip(labels,detail):\n",
    "        detail_type[str(l.text)]=d.text\n",
    "\n",
    "    review_t=pd.DataFrame.from_dict(reviews, orient='index').reset_index()\n",
    "    review_t.columns=['review','score']\n",
    "    review_t['name']=class_name\n",
    "    review_t['prof']=prof_name\n",
    "    \n",
    "    review_detail=pd.DataFrame.from_dict(detail_type,orient='index').T\n",
    "    review_detail['name']=class_name\n",
    "    review_detail['prof']=prof_name\n",
    "\n",
    "    \n",
    "    #return review_t,review_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_vector(model,corpus):\n",
    "    \n",
    "    embeding_dict={}\n",
    "    embeding_df=pd.DataFrame()\n",
    "    for w,v in zip(model.wv.index2word , model.wv.vectors):\n",
    "        embeding_dict[w]=v\n",
    "        embeding_table=(pd.DataFrame(embeding_dict).T.reset_index())\n",
    "    for words in (corpus):\n",
    "        embeding_df=pd.concat([embeding_df,\n",
    "                               embeding_table.query('@words in index').iloc[:,1:].mean()]\n",
    "                             ,axis=1 )\n",
    "    return embeding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_embedding_update():\n",
    "    review = pd.DataFrame() # 강의평 추출 테이블\n",
    "    detail = pd.DataFrame() # 과목 세부정보 추출 테이블\n",
    "\n",
    "    \n",
    "    #링크 가져오기\n",
    "    fname = input('lecture의 버전을 입력해주세요')\n",
    "    lecture = pd.read_csv(str(fname))\n",
    "    lecture = lecture.query('score != 0')\n",
    "    link_list=list(lecture['link'].unique())\n",
    "    link_list.remove('javascript: alert(\"%EC%95%84%EC%A7%81 %EB%93%B1%EB%A1%9D%EB%90%9C %EA%B0%95%EC%9D%98%ED%8F%89%EC%9D%B4 %EC%97%86%EC%8A%B5%EB%8B%88%EB%8B%A4.\");')\n",
    "\n",
    "    \n",
    "    # ↓ 가끔 안 켜고 시작하면 오류뜰 때가 있어서 그때 대비 \n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(link_list[0]) \n",
    "    login(id_,password)\n",
    "    # ↑ 가끔 안 켜고 시작하면 오류뜰 때가 있어서 그때 대비 \n",
    "\n",
    "\n",
    "    # 크롤링 과정\n",
    "    for link in tqdm_notebook(link_list) :\n",
    "        try:\n",
    "            r_t,r_d=review_crawl(link)\n",
    "            review=pd.concat([review,r_t])\n",
    "            detail=pd.concat([detail,r_d])\n",
    "            sleep(1)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # 특문 없애기\n",
    "    clean=[]\n",
    "    for data in review['review']:\n",
    "        clean.append(cleanText(data))\n",
    "    review['review']=pd.Series(clean)\n",
    "\n",
    "    file_write(review,review)\n",
    "    file_write(detail,detail)\n",
    "    \n",
    "    kkma = Kkma()  \n",
    "    corpus=[] \n",
    "    \n",
    "    for data in tqdm(review['review']):\n",
    "        try:\n",
    "            corpus.append(kkma.morphs(data))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    size = 100\n",
    "    \n",
    "    embd_SG= Word2Vec(corpus, size=size ,window=2, min_count=10,\n",
    "                           workers=-1, iter=1000, sg=1)\n",
    "    \n",
    "    embedding_vect=get_embedding_vector(embd_SG,corpus)\n",
    "    \n",
    "    vect=(embedding_vect.T.reset_index()).iloc[:,1:] # 데이터 프레임으로 바꿔주고\n",
    "    vect.columns=['Review_Embeded'+str(x) for x in range(size)] # 칼럼이름도 달아줌\n",
    "\n",
    "    # 리뷰랑 병합(Group화 해서 강의별 계산을 위함)\n",
    "    review.index=range(len(review))\n",
    "    embd=pd.concat([review.iloc[:,1:],vect],axis=1)\n",
    "\n",
    "    # 여기다 담아놓은다음에 Merge\n",
    "    feature=[]\n",
    "    \n",
    "    for col_name in (['Review_Embeded'+str(x) for x in range(size)]):\n",
    "        feature.append(embd.groupby(['name','prof'])[col_name].mean().reset_index())\n",
    "        \n",
    "    lecture = lecture.drop(['class_code','time','link','competitor'],axis=1)\n",
    "    lecture.rename({'class_name':'name','professor':'prof'},axis=1,inplace=True)\n",
    "\n",
    "    for f in feature :\n",
    "        df = pd.merge(lecture, f, on=['name','prof'],how='left')\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sim_df=pd.concat([df[['name','prof',]],df.iloc[:,7:]],axis=1)\n",
    "    sim_df.index=[x for x in range(len(sim_df))]\n",
    "    file_write(sim_df,sim_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도 계산 함수\n",
    "def cos_sim(A, B): \n",
    "       return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 모든 행과 유사도 계산 함수\n",
    "def find_similar(input_name,input_prof,df):\n",
    "    input_lecture=df.query('name == @input_name & prof == @input_prof')\n",
    "    rest_lecture=df.query('name != @input_name | prof != @input_prof')\n",
    "    output=rest_lecture.iloc[:,:2]\n",
    "    output['similar']=''\n",
    "    for i in range(len(rest_lecture)):\n",
    "        output.iloc[i,2]= cos_sim(input_lecture.iloc[:,2:],rest_lecture.iloc[i,2:])\n",
    "    output = pd.merge(output, detail_table, on=['name','prof'],how='left')\n",
    "    output = output.sort_values('similar',ascending=False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all():\n",
    "    lecture_update()\n",
    "    review_embedding_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_data_all():\n",
    "    os.listdir()\n",
    "    ver=input('버전을 입력하세요')\n",
    "    lecture=pd.read_csv('lecture'+str(ver)+'.csv')\n",
    "    review=pd.read_csv('review'+str(ver)+'.csv')\n",
    "    detail=pd.read_csv('detail'+str(ver)+'.csv')\n",
    "    sim_df=pd.read_csv('sim_df'+str(ver)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
